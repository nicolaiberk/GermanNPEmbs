{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Kopie von Kopie von emb_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolaiberk/GermanNPEmbs/blob/main/emb_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa9mxZGMoEdK",
        "outputId": "132b577b-a441-4d8d-d729-fc9ad210fdff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "qa9mxZGMoEdK",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5825374-c511-47fe-a2e4-da9bd8431a6d",
        "outputId": "58137c9c-4585-46a4-e42d-5bcb2872e995"
      },
      "source": [
        "## estimate word embeddings from newspaper data\n",
        "## code adapted from https://github.com/damian0604/embeddingworkshop/blob/main/04exercise.ipynb\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import string\n",
        "import re\n",
        "import os\n",
        "import pandas as pd\n",
        "import csv\n",
        "import sys\n",
        "import ast\n",
        "import time\n",
        "\n",
        "\n",
        "# tqdm allows you to display progress bars in loops\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "import gensim\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "# lets get more output\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "drivepath = 'drive/MyDrive/Bild/'"
      ],
      "id": "c5825374-c511-47fe-a2e4-da9bd8431a6d",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11c85d9f-4750-470f-8ff8-a0a91dc705c6"
      },
      "source": [
        "# get full set of news articles\n",
        "if not os.path.isfile('newspapers/_bild_articles.csv') and not os.path.isfile(drivepath+'uniquesentences.txt'):\n",
        "    os.system('mkdir newspapers')\n",
        "    os.system('wget -O newspapers/articles.zip https://www.dropbox.com/sh/r6k4qk9flgz0agu/AAA5ZLsuOwk9UWiEsLAOFmDSa?dl=0')\n",
        "    os.system('unzip newspapers/articles.zip -d newspapers')\n",
        "    os.system('rm newspapers/articles.zip')"
      ],
      "id": "11c85d9f-4750-470f-8ff8-a0a91dc705c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz3OYCGmcSXU"
      },
      "source": [
        "if not os.path.isfile(drivepath+'uniquesentences.txt'):\n",
        "  # load all texts\n",
        "  if 'artcls' not in locals():\n",
        "    for filename in tqdm(os.listdir('newspapers')):\n",
        "      if 'artcls' in locals():\n",
        "        print(f'\\nLoaded {artcls.shape[0]} articles')\n",
        "        artcls = artcls.append(pd.read_csv('newspapers/'+filename))\n",
        "      else:\n",
        "        artcls = pd.read_csv('newspapers/'+filename)\n",
        "    print(f'Loaded {artcls.shape[0]} articles, done.')\n",
        "\n",
        "    artcls = artcls.reset_index()\n",
        "\n",
        "\n",
        "  # keep only if string\n",
        "  stringvar = [str == type(i) for i in artcls.text]\n",
        "  artcls = artcls[stringvar]\n",
        "  del(stringvar)\n",
        "\n",
        "  print(artcls.text[0])"
      ],
      "id": "lz3OYCGmcSXU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN7u7PUswUWQ"
      },
      "source": [
        "if not os.path.isfile(drivepath+'uniquesentences.txt'):\n",
        "  # subset\n",
        "  artcls = artcls.text"
      ],
      "id": "SN7u7PUswUWQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpA0PEMXdFAF"
      },
      "source": [
        "if not os.path.isfile(drivepath+'uniquesentences.txt'):\n",
        "  # cut into sentences\n",
        "  print('\\nCutting into sentences:')\n",
        "  uniquesentences = set()\n",
        "  trans = str.maketrans('', '', string.punctuation) # translation scheme for removing punctuation\n",
        "  for review in tqdm(artcls):\n",
        "    sentences = sent_tokenize(review) \n",
        "    for sentence in sentences:\n",
        "      sent_trans = sentence.translate(trans).lower()\n",
        "      if sent_trans not in uniquesentences:\n",
        "        uniquesentences.add(sent_trans)\n",
        "\n",
        "  del(artcls)"
      ],
      "id": "zpA0PEMXdFAF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCRZzFiXkw9t"
      },
      "source": [
        "if not os.path.isfile(drivepath+'uniquesentences.txt'):\n",
        "  # extract \n",
        "  print(f\"We now have {len(uniquesentences)} unique sentences.\")"
      ],
      "id": "oCRZzFiXkw9t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNK2emCxgmeT"
      },
      "source": [
        "if not os.path.isfile(drivepath+'uniquesentences.txt'):\n",
        "  with open('uniquesentences.txt', 'w') as fo:\n",
        "    writer = csv.writer(fo)\n",
        "    for sentence in tqdm(uniquesentences):\n",
        "      writer.writerow([sentence])"
      ],
      "id": "WNK2emCxgmeT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdZH3Hz9nS-b",
        "outputId": "9eea322e-ca3c-43ee-8741-3deb08b2d1d9"
      },
      "source": [
        "if os.path.isfile(drivepath+'uniquesentences.txt'):\n",
        "  with open(drivepath+'uniquesentences.txt') as fi:\n",
        "    uniquesentences = fi.readlines()\n",
        "  print(f\"We now have {len(uniquesentences)} unique sentences.\")"
      ],
      "id": "xdZH3Hz9nS-b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We now have 42302049 unique sentences.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0N3yLWzParU"
      },
      "source": [
        "tokenizedsentences = (sentence.split() for sentence in uniquesentences) # iterator for vocab definition"
      ],
      "id": "U0N3yLWzParU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UjJAa6-VxL9"
      },
      "source": [
        "inp = drivepath+\"uniquesentences.txt\""
      ],
      "id": "1UjJAa6-VxL9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spkoV479rBV9"
      },
      "source": [
        "print(f\"Started setting up the model at {datetime.now()}\")\n",
        "model = gensim.models.Word2Vec(size=300, min_count=100, window = 5, workers = 4) # we want 300 dimensions and not overdo it with the features\n",
        "model.build_vocab(tokenizedsentences)\n",
        "print(f\"Finished vocabulary definition at {datetime.now()}\")"
      ],
      "id": "spkoV479rBV9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwrDK1apYKi8"
      },
      "source": [
        "del(uniquesentences)"
      ],
      "id": "GwrDK1apYKi8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3WhP1wR4r7K"
      },
      "source": [
        "from gensim.models.word2vec import LineSentence\n",
        "\n",
        "print(f\"Started training at {datetime.now()}\")\n",
        "model.train(LineSentence(inp), total_examples=model.corpus_count,  epochs=5)\n",
        "print(f\"Finished training at {datetime.now()}\")"
      ],
      "id": "N3WhP1wR4r7K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-2XB8dQu6Cl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1693d04-1408-490c-fd74-0cc3f32c70ba"
      },
      "source": [
        "print('Saving model:')\n",
        "model.save(drivepath+\"np_emb\")\n",
        "print('Model finished!')"
      ],
      "id": "J-2XB8dQu6Cl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-09 20:47:49,576 : INFO : saving Word2Vec object under drive/MyDrive/Bild/np_emb, separately None\n",
            "2021-08-09 20:47:49,584 : INFO : storing np array 'vectors' to drive/MyDrive/Bild/np_emb.wv.vectors.npy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving model:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-09 20:47:51,228 : INFO : not storing attribute vectors_norm\n",
            "2021-08-09 20:47:51,230 : INFO : storing np array 'syn1neg' to drive/MyDrive/Bild/np_emb.trainables.syn1neg.npy\n",
            "2021-08-09 20:47:53,564 : INFO : not storing attribute cum_table\n",
            "2021-08-09 20:47:54,312 : INFO : saved drive/MyDrive/Bild/np_emb\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ha2RB9E8uED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56cefd7a-3fcc-4010-f733-c8974a0879ce"
      },
      "source": [
        "# Store just the words + their trained embeddings.\n",
        "model = gensim.models.Word2Vec.load(drivepath+\"np_emb\")\n",
        "word_vectors = model.wv\n",
        "word_vectors.save(drivepath+\"word2vec.wordvectors\")"
      ],
      "id": "9ha2RB9E8uED",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-10 09:51:10,824 : INFO : loading Word2Vec object from drive/MyDrive/Bild/np_emb\n",
            "2021-08-10 09:51:12,687 : INFO : loading wv recursively from drive/MyDrive/Bild/np_emb.wv.* with mmap=None\n",
            "2021-08-10 09:51:12,689 : INFO : loading vectors from drive/MyDrive/Bild/np_emb.wv.vectors.npy with mmap=None\n",
            "2021-08-10 09:51:15,523 : INFO : setting ignored attribute vectors_norm to None\n",
            "2021-08-10 09:51:15,524 : INFO : loading vocabulary recursively from drive/MyDrive/Bild/np_emb.vocabulary.* with mmap=None\n",
            "2021-08-10 09:51:15,526 : INFO : loading trainables recursively from drive/MyDrive/Bild/np_emb.trainables.* with mmap=None\n",
            "2021-08-10 09:51:15,527 : INFO : loading syn1neg from drive/MyDrive/Bild/np_emb.trainables.syn1neg.npy with mmap=None\n",
            "2021-08-10 09:51:18,484 : INFO : setting ignored attribute cum_table to None\n",
            "2021-08-10 09:51:18,485 : INFO : loaded drive/MyDrive/Bild/np_emb\n",
            "2021-08-10 09:51:18,953 : INFO : saving Word2VecKeyedVectors object under drive/MyDrive/Bild/word2vec.wordvectors, separately None\n",
            "2021-08-10 09:51:18,954 : INFO : storing np array 'vectors' to drive/MyDrive/Bild/word2vec.wordvectors.vectors.npy\n",
            "2021-08-10 09:51:19,593 : INFO : not storing attribute vectors_norm\n",
            "2021-08-10 09:51:19,959 : INFO : saved drive/MyDrive/Bild/word2vec.wordvectors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBFlf0_lYQDk"
      },
      "source": [
        "Assess model validity"
      ],
      "id": "UBFlf0_lYQDk"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXCjolwu9MM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b837bb3-d569-4f55-c89b-ef84c54a63db"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "wv = KeyedVectors.load(drivepath+\"word2vec.wordvectors\", mmap='r')"
      ],
      "id": "GXCjolwu9MM6",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-10 09:51:40,140 : INFO : loading Word2VecKeyedVectors object from drive/MyDrive/Bild/word2vec.wordvectors\n",
            "2021-08-10 09:51:40,641 : INFO : loading vectors from drive/MyDrive/Bild/word2vec.wordvectors.vectors.npy with mmap=r\n",
            "2021-08-10 09:51:40,662 : INFO : setting ignored attribute vectors_norm to None\n",
            "2021-08-10 09:51:40,663 : INFO : loaded drive/MyDrive/Bild/word2vec.wordvectors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjr7esAa9Py7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56a7092b-b448-480c-b928-a045234503bc"
      },
      "source": [
        "word_vectors.most_similar('flüchtling', topn=10)  # get other similar words"
      ],
      "id": "wjr7esAa9Py7",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('kriegsflüchtling', 0.7599212527275085),\n",
              " ('migrant', 0.7159389853477478),\n",
              " ('asylsuchender', 0.6973713040351868),\n",
              " ('afghane', 0.669090747833252),\n",
              " ('syrer', 0.6585391759872437),\n",
              " ('asylbewerber', 0.6557232141494751),\n",
              " ('häftling', 0.6416419744491577),\n",
              " ('flüchtlingskind', 0.6333128213882446),\n",
              " ('kurde', 0.6098465919494629),\n",
              " ('eritreer', 0.6053134202957153)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u33HxMZWeZs6",
        "outputId": "7d384003-dfda-411a-a989-3c532f4bb6b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_vectors.most_similar('immigration', topn=10)"
      ],
      "id": "u33HxMZWeZs6",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('einwanderung', 0.8021354079246521),\n",
              " ('migration', 0.7246120572090149),\n",
              " ('zuwanderung', 0.670327365398407),\n",
              " ('einwanderung“', 0.6148055791854858),\n",
              " ('migration“', 0.6068947315216064),\n",
              " ('arbeitsmigration', 0.5892990827560425),\n",
              " ('masseneinwanderung', 0.5891662836074829),\n",
              " ('sekundärmigration', 0.5775723457336426),\n",
              " ('armutsmigration', 0.5755099058151245),\n",
              " ('immigranten', 0.5382981896400452)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuVq4qIWfKua",
        "outputId": "1c272bd2-5c42-400e-ec17-84a31c5f4726",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_vectors.most_similar(positive=[\"frau\",\"könig\"],negative=[\"mann\"])"
      ],
      "id": "tuVq4qIWfKua",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('königin', 0.6508051156997681),\n",
              " ('gemahlin', 0.6460778713226318),\n",
              " ('prinzessin', 0.6355438232421875),\n",
              " ('gattin', 0.6281205415725708),\n",
              " ('kaiserin', 0.5999823808670044),\n",
              " ('mätresse', 0.5790205597877502),\n",
              " ('fürstin', 0.5617177486419678),\n",
              " ('hofdame', 0.5549862384796143),\n",
              " ('kronprinzessin', 0.5427185297012329),\n",
              " ('ehefrau', 0.5426924228668213)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3zWGmo4f3se",
        "outputId": "d4ca2116-ace2-4e05-af1d-1cd665833aa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_vectors.most_similar(positive=[\"sie\",\"arzt\"],negative=[\"er\"]) # surprisingly unbiased on gender"
      ],
      "id": "z3zWGmo4f3se",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('gynäkologen', 0.6619372367858887),\n",
              " ('frauenarzt', 0.6503668427467346),\n",
              " ('hausarzt', 0.647055983543396),\n",
              " ('kinderarzt', 0.6321763396263123),\n",
              " ('urologen', 0.6317317485809326),\n",
              " ('ärzte', 0.6316326856613159),\n",
              " ('orthopäden', 0.629375696182251),\n",
              " ('mediziner', 0.6273952722549438),\n",
              " ('therapeuten', 0.6148329973220825),\n",
              " ('kardiologen', 0.6140260696411133)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smDJLjUKfU5p",
        "outputId": "7a58a0d3-5f38-43fe-ea63-74dbeac2cb56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_vectors.most_similar(positive=[\"frau\",\"arzt\"],negative=[\"mann\"]) # surprisingly unbiased on gender"
      ],
      "id": "smDJLjUKfU5p",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ärztin', 0.7049057483673096),\n",
              " ('therapeutin', 0.6990090608596802),\n",
              " ('gynäkologin', 0.6784191727638245),\n",
              " ('patientin', 0.6637605428695679),\n",
              " ('hebamme', 0.6561906933784485),\n",
              " ('frauenärztin', 0.6545000672340393),\n",
              " ('kinderärztin', 0.6402939558029175),\n",
              " ('zahnärztin', 0.6391436457633972),\n",
              " ('hausärztin', 0.634697675704956),\n",
              " ('pflegerin', 0.63043212890625)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH4d6r1Kffus",
        "outputId": "8f215434-7140-408e-ebda-8bc246fcfff6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_vectors.most_similar(positive=[\"marokkaner\",\"polizist\"],negative=[\"deutscher\"])"
      ],
      "id": "wH4d6r1Kffus",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('mann', 0.6420572996139526),\n",
              " ('messerstecher', 0.6257760524749756),\n",
              " ('afghane', 0.6227939128875732),\n",
              " ('angeklagte', 0.6134068965911865),\n",
              " ('algerier', 0.611687421798706),\n",
              " ('wachmann', 0.6098835468292236),\n",
              " ('sicherheitsmann', 0.6046900749206543),\n",
              " ('tunesier', 0.5988072156906128),\n",
              " ('taxifahrer', 0.5979149341583252),\n",
              " ('eritreer', 0.5968226194381714)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}